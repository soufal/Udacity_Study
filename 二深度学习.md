### 二、深度学习

深度学习最重要的组成部分为：Neural Networks（神经网络）------*模仿大脑操作过程，并通过神经元发射零零散散的信息。*

#### 感知器（perceptron）：

指的是把方程式进行编码，形成小图形。

![image-20200127205850913](image\image-20200127205850913.png)





![image-20200127205945797](image\image-20200127205945797.png)

![image-20200127210102424](image\image-20200127210102424.png)

##### 阶跃函数（step function）：

![image-20200127210223667](image\image-20200127210223667.png)

![image-20200127210247087](image\image-20200127210247087.png)

#### 感知器算法：    



![image-20200128163007427](image\image-20200128163007427.png)

感知器步骤如下所示。对于坐标轴为 (p,q)(*p*,*q*) 的点，标签 y，以及等式$ \hat{y} = step(w_1x_1 + w_2x_2 + b)$给出的预测

- 如果点分类正确，则什么也不做。
- 如果点分类为正，但是标签为负，则分别减去$ \alpha p, \alpha q$, 和 $\alpha$ 至 $w_1, w_2$, 和 $b$.
- 如果点分类为负，但是标签为正，则分别将$ \alpha p, \alpha q$,和 $\alpha$ 加到 $w_1, w_2$,和 $b$ 上。

```python
import numpy as np
# Setting the random seed, feel free to change it and see different solutions.
np.random.seed(22)

def stepFunction(t):
    if t >= 0:
        return 1
    return 0

def prediction(X, W, b):
    return stepFunction((np.matmul(X,W)+b)[0])

# TODO: Fill in the code below to implement the perceptron trick.
# The function should receive as inputs the data X, the labels y,
# the weights W (as an array), and the bias b,
# update the weights and bias W, b, according to the perceptron algorithm,
# and return W and b.
def perceptronStep(X, y, W, b, learn_rate = 0.01):
    # Fill in code
    for i in range(len(X)):
        y_hat = prediction(X[i], W, b)
        if y_hat != y[i]:
            if y_hat == 1:
                W[0] = W[0] - learn_rate * X[i][0]
                W[1] = W[1] - learn_rate * X[i][1]
                b = b - learn_rate
            elif y_hat == 0:
                W[0] = W[0] + learn_rate * X[i][0]
                W[1] = W[1] + learn_rate * X[i][1]
                b = b + learn_rate
        else:
            pass
    return W, b

# This function runs the perceptron algorithm repeatedly on the dataset,
# and returns a few of the boundary lines obtained in the iterations,
# for plotting purposes.
# Feel free to play with the learning rate and the num_epochs,
# and see your results plotted below.
def trainPerceptronAlgorithm(X, y, learn_rate = 0.01, num_epochs = 25):
    x_min, x_max = min(X.T[0]), max(X.T[0])
    y_min, y_max = min(X.T[1]), max(X.T[1])
    W = np.array(np.random.rand(2,1))
    b = np.random.rand(1)[0] + x_max
    # These are the solution lines that get plotted below.
    boundary_lines = []
    for i in range(num_epochs):
        # In each epoch, we apply the perceptron step.
        W, b = perceptronStep(X, y, W, b, learn_rate)
        boundary_lines.append((-W[0]/W[1], -b/W[1]))
    return boundary_lines

```

```csv
0.78051,-0.063669,1
0.28774,0.29139,1
0.40714,0.17878,1
0.2923,0.4217,1
0.50922,0.35256,1
0.27785,0.10802,1
0.27527,0.33223,1
0.43999,0.31245,1
0.33557,0.42984,1
0.23448,0.24986,1
0.0084492,0.13658,1
0.12419,0.33595,1
0.25644,0.42624,1
0.4591,0.40426,1
0.44547,0.45117,1
0.42218,0.20118,1
0.49563,0.21445,1
0.30848,0.24306,1
0.39707,0.44438,1
0.32945,0.39217,1
0.40739,0.40271,1
0.3106,0.50702,1
0.49638,0.45384,1
0.10073,0.32053,1
0.69907,0.37307,1
0.29767,0.69648,1
0.15099,0.57341,1
0.16427,0.27759,1
0.33259,0.055964,1
0.53741,0.28637,1
0.19503,0.36879,1
0.40278,0.035148,1
0.21296,0.55169,1
0.48447,0.56991,1
0.25476,0.34596,1
0.21726,0.28641,1
0.67078,0.46538,1
0.3815,0.4622,1
0.53838,0.32774,1
0.4849,0.26071,1
0.37095,0.38809,1
0.54527,0.63911,1
0.32149,0.12007,1
0.42216,0.61666,1
0.10194,0.060408,1
0.15254,0.2168,1
0.45558,0.43769,1
0.28488,0.52142,1
0.27633,0.21264,1
0.39748,0.31902,1
0.5533,1,0
0.44274,0.59205,0
0.85176,0.6612,0
0.60436,0.86605,0
0.68243,0.48301,0
1,0.76815,0
0.72989,0.8107,0
0.67377,0.77975,0
0.78761,0.58177,0
0.71442,0.7668,0
0.49379,0.54226,0
0.78974,0.74233,0
0.67905,0.60921,0
0.6642,0.72519,0
0.79396,0.56789,0
0.70758,0.76022,0
0.59421,0.61857,0
0.49364,0.56224,0
0.77707,0.35025,0
0.79785,0.76921,0
0.70876,0.96764,0
0.69176,0.60865,0
0.66408,0.92075,0
0.65973,0.66666,0
0.64574,0.56845,0
0.89639,0.7085,0
0.85476,0.63167,0
0.62091,0.80424,0
0.79057,0.56108,0
0.58935,0.71582,0
0.56846,0.7406,0
0.65912,0.71548,0
0.70938,0.74041,0
0.59154,0.62927,0
0.45829,0.4641,0
0.79982,0.74847,0
0.60974,0.54757,0
0.68127,0.86985,0
0.76694,0.64736,0
0.69048,0.83058,0
0.68122,0.96541,0
0.73229,0.64245,0
0.76145,0.60138,0
0.58985,0.86955,0
0.73145,0.74516,0
0.77029,0.7014,0
0.73156,0.71782,0
0.44556,0.57991,0
0.85275,0.85987,0
0.51912,0.62359,0
```

#### 误差函数（Error function）与梯度下降：    

误差函数提供给我们的预测值与实际值之间的差异，但是这个差异如何指导我们权重的更新呢？我们的目标是找到**最小**的误差函数值来找到与实际值误差最小的预测值。

在简单的线性方程中，我们可以通过判断“预测值与实测值相比是大了还是小了”来决定权重是增加还是减少。但是在更为复杂的非线性环境中呢？复杂的数学问题，我们就直接来看看学者们的解决策略。

假设一维问题是一条直线，那么二维问题就是一个平面，而三维问题就是一个曲面。曲面可以理解为有山峰也有低谷的地面，误差最小的地方就是低谷处，我们希望计算机找到的就是这个低谷的值。为了找到这个低谷，学者们发明了**梯度下降**。

> 用数学术语描述，为了进行梯度下降，误差函数（error function）不能是离散的，必须是连续的。因为位置上的轻微变化就会导致高度发生变化。**误差函数必须是可微分的。**

#### 离散型与连续性预测：

对于优化而言，连续型误差函数比离散型函数（只有1或0输出来表示分类）更好。为此，我们需要从离散型预测变成连续型预测。

![image-20200128173039357](image\image-20200128173039357.png)

* **概率是关于点离直线距离的函数。**

![image-20200128173453340](image\image-20200128173453340.png)



![image-20200128173652393](image\image-20200128173652393.png)



![image-20200128173823836](image\image-20200128173823836.png)

#### 多类别分类和Softmax：   

* Softmax函数：是激活函数的对等形式。它和s型函数是对等的，但是问题具有3个或更多个类别。

![image-20200128202104067](image\image-20200128202104067.png)

* Softmax Function:

  * 假如有n个类别和线性模型，可以得到下列分数：

  ![image-20200128202552759](image\image-20200128202552759.png)

  **答案为是的。**

  * 编写$Softmax$函数：

  ```python
  '''
  方法一
  '''
  import numpy as np
  
  # Write a function that takes as input a list of numbers, and returns
  # the list of values given by the softmax function.
  def softmax(L):
      sum_L = sum(np.exp(L))
      # print(sum_L)
      return np.exp(L) / sum_L
  
  '''
  方法二
  '''
  import numpy as np
  
  def softmax(L):
      expL = np.exp(L)
      sumExpL = sum(expL)
      result = []
      for i in expL:
          result.append(i*1.0/sumExpL)
      return result
      
      # Note: The function np.divide can also be used here, as follows:
      # def softmax(L):
      #     expL = np.exp(L)
      #     return np.divide (expL, expL.sum())
  
  ```

  

#### One-Hot 编码：

计算机在表示多结果的分类时，使用One-Hot编码是比较常见的处理方式。

#### 最大似然率（maximum Likelihood）：

> 最佳模型更有可能是对于实际在我们身上发生情况所对应的概率更大的模型。

##### 最大化概率（maximum probability）：

等价于最小化误差函数。

#### 交叉熵（Cross Entropy）---损失函数：

* 可以看作是概率和误差函数之间的联系。

* 特性：

  * 如果有一系列的时间及其对应的发生概率，根据这些概率，这些时间发生的可能性有多大？
    * 如果可能性大，则交叉熵较小。
    * 如果可能性小，那么交叉熵就会很大。

  ![image-20200128215411682](image\image-20200128215411682.png)

* 准确的模型可以得到较低的交叉熵，误差较大的模型得到的交叉熵较高。

* 可以将每个数据点的交叉熵作为该点的误差。

* **目标可以从最大化概率转变为最小化交叉熵。**

![image-20200128213926797](image\image-20200128213926797.png)

```python
'''
方法一
'''
import numpy as np

# Write a function that takes as input two lists Y, P,
# and returns the float corresponding to their cross-entropy.
def cross_entropy(Y, P):
    result = 0
    for i in range(len(Y)):
        result += Y[i] * np.log(P[i]) + (1-Y[i]) * np.log(1-P[i])

    return -result


'''
方法二
'''
import numpy as np

def cross_entropy(Y, P):
    Y = np.float_(Y)
    P = np.float_(P)
    return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))
```

##### 多类别交叉熵：     

* 交叉熵与结果的总概率成反比。

#### logistic 回归： 

**对数几率回归**算法。基本上是这样的：

- 获得数据
- 选择一个随机模型
- 计算误差
- 最小化误差，获得更好的模型
- 完成！

##### 计算误差函数：

![image-20200128233638873](image\image-20200128233638873.png)

![image-20200128233758388](image\image-20200128233758388.png)



![image-20200128233832785](image\image-20200128233832785.png)



##### 最小化误差函数：

**主要使用梯度下降法。**      

#### 梯度下降：     

* $E$的梯度为相对于权重$W$偏导数的矢量和。
* 这个梯度实际上就是误差函数式增长最快的方向。该梯度的反方向则是误差函数降低最快的方向。

# 梯度计算

在上几个视频中，我们了解到为了最小化误差函数，我们需要获得一些导数。我们开始计算误差函数的导数吧。首先要注意的是 s 型函数具有很完美的导数。即

$$\sigma'(x) = \sigma(x) (1-\sigma(x))$$

原因是，我们可以使用商式计算它：



[![img](image\codecogseqn-49.gif)]()



现在，如果有 *m* 个样本点，标为 $x^{(1)}, x^{(2)}, \ldots, x^{(m)}$ 误差公式是：

$$E = -\frac{1}{m} \sum_{i=1}^m \left( y^{(i)} \ln(\hat{y^{(i)}}) + (1-y^{(i)}) \ln (1-\hat{y^{(i)}}) \right)$$

预测是 $\hat{y^{(i)}} = \sigma(Wx^{(i)} + b).$

我们的目标是计算 E,*E*, 在单个样本点 x 时的梯度（偏导数），其中 x 包含 n 个特征，即$x = (x_1, \ldots, x_n)$。

$$\nabla E =\left(\frac{\partial}{\partial w_1}E, \cdots, \frac{\partial}{\partial w_n}E, \frac{\partial}{\partial b}E \right)$$

为此，首先我们要计算，$\frac{\partial}{\partial w_j} \hat{y}$.

因为这是上述公式里的第一个元素。

$\hat{y} = \sigma(Wx+b)$, 因此：



[![img](image\codecogseqn-43.gif)](https://classroom.udacity.com/nanodegrees/nd025-cn/parts/fecc645f-8b1f-4d73-9754-7b7b380f01e8/modules/afa2a1d2-faba-4f05-a5e3-2759e1336e91/lessons/00912248-2445-4713-ad9c-76b8536e1959/concepts/0d92455b-2fa0-4eb8-ae5d-07c7834b8a56#)



最后一个等式是因为和中的唯一非常量项相对于 $w_j$ 正好是 $w_j x_j$, 明显具有导数 $x_j.$.

现在可以计算 $\frac {\partial} {\partial w_j}E$

[![img](image\codecogseqn-60-2.png)](https://classroom.udacity.com/nanodegrees/nd025-cn/parts/fecc645f-8b1f-4d73-9754-7b7b380f01e8/modules/afa2a1d2-faba-4f05-a5e3-2759e1336e91/lessons/00912248-2445-4713-ad9c-76b8536e1959/concepts/0d92455b-2fa0-4eb8-ae5d-07c7834b8a56#)



类似的计算将得出：（备注：下图公式缺少一个负号，且其为 m 个样本点时的公式）

【针对单个样本点时，E 对 b 求偏导的公式为：$\frac {\partial} {\partial b} E=-(y -\hat{y})$】

[![img](image\codecogseqn-58.gif)](https://classroom.udacity.com/nanodegrees/nd025-cn/parts/fecc645f-8b1f-4d73-9754-7b7b380f01e8/modules/afa2a1d2-faba-4f05-a5e3-2759e1336e91/lessons/00912248-2445-4713-ad9c-76b8536e1959/concepts/0d92455b-2fa0-4eb8-ae5d-07c7834b8a56#)



这个实际上告诉了我们很重要的规则。对于具有坐标$ (x_1, \ldots, x_n)$, 的点，标签 $y$, 预测 $\hat{y}$, 该点的误差函数梯度是 $\left(-(y - \hat{y})x_1, \cdots, -(y - \hat{y})x_n, -(y - \hat{y}) \right)$.

总之

$$\nabla E(W,b) = -(y - \hat{y}) (x_1, \ldots, x_n, 1).$$

如果思考下，会发现很神奇。梯度实际上是标量乘以点的坐标！什么是标量？也就是标签和预测之间的差别。这意味着，如果标签与预测接近（表示点分类正确），该梯度将很小，如果标签与预测差别很大（表示点分类错误），那么此梯度将很大。请记下：小的梯度表示我们将稍微修改下坐标，大的梯度表示我们将大幅度修改坐标。

##### 梯度下降步骤

因此，梯度下降的简单步骤包括减去每点的误差函数的梯度与学习速率的乘积，然后按以下方式更新权重：

$$w_i' \leftarrow w_i -\alpha [-(y - \hat{y}) x_i]$$

这相当于

$$w_i' \leftarrow w_i + \alpha (y - \hat{y}) x_i$$

类似地，它以如下方式更新偏差：

$$b' \leftarrow b + \alpha (y - \hat{y})$$

*注意：*因为我们取了这些误差的平均值，我们要添加的这项应该是 $\frac{1}{m} \cdot \alpha$而不是 $\alpha$,但因为$\alpha$是一个常量，为简化计算，我们仅取 $\frac{1}{m} \cdot \alpha$ 作为学习速率并且用这个符号来表示 $\alpha.$