### 一、数据科学流程   

#### （一）CRISP-DM(Cross-Industry Standard Process for Data Mining跨行业数据挖掘标准流程)流程  

1. 业务理解：**理解你所在领域的业务相关问题。（也就是针对业务需求提出相关问题。）**例如：
   1. 如何获得新客户？
   2. 新的治疗方案是否优于旧有方案？
   3. 如何改善沟通？
   4. 如何提升旅游体验？
   5. 如何更好地保留信息？
2. 数据理解：**需要将业务理解的问题跟数据联系起来，在已有数据的基础上，也需要额外收集更多的数据来回答业务理解中所提出来的问题。**
   1. 如何入门技术领域？
   2. 参加编程训练营对就业和工资是否有帮助？
   3. 如何预测工资？工资与哪些因素有相关性？
   4. 如何预测工作满意度？工作满意度与哪些因素有相关性？
3. 数据准备：*数据清洗占据了数据分析整个流程中 80% 的时间。*
4. 建模
5. 评估结果
6. 部署

#### Important：    

##### Pandas：  

1. 判断$DataFrame$中哪些列没有缺失值，并给出这些列名:

   ```python
   #方法一：
   no_nulls = set(df.columns[df.isnull().mean()==0])
   #方法二：
   no_nulls = set(df.columns[np.sum(df.isnull())==0])
   ```

   

2. 给出所有缺失值比例高于75%的列名：

   ```python
   #方法一:
   most_missing_cols = set(df.columns[df.isnull().mean()>0.75])
   #方法二：
   no_nulls = set(df.columns[np.sum(df.isnull())/df.shap[0] > 0.75])
   ```
   
3. 统计某一类列中值的出现次数:  

   ```python
   #使用groupby分组后统计，该方法得到的结果是按照原本数据中的值进行排序的。
   Gender_cals = df.groupby('Gender').size()
   #使用value_counts()方法，得到的结果是按照次数来进行排序输出的（从大到小）。
   Gender_cals = df.loc[:,'Gender'].value_counts()
   Gender_cals = df['Gender'].value_counts()
   Gender_cals = df.Gender.value_counts()
   ```

   


#### （二）是否必须用机器学习建模？   

##### 解答数据科学问题的必备技能

1. 好奇心

   

2. **正确**的数据

   

3. 类似 Python、Tableau、Excel、R 这样的工具，能帮你找到答案（尤其当数据量非常大的时候，就不能只用自己的大脑来计算了）

   

4. 经过良好沟通和部署的解决方案

##### 额外的但不是对所有项目都有用的工具

- 深度学习
- 机器学习算法

后面会涉及这些内容，但是值得说明的是，它们并不能解决所有的问题。**深度学习无法基于“坏数据”得出好的结论，或者对不合理的问题给出有趣的结果。**很多实际的数据科学问题，其实是要回答问题。

#### （三）建模：

对于以下两个问题，我们需要建模。

1. 如何预测工资？工资与哪些因素有相关性？
2. 如何预测工作满意度？工作满意度与哪些因素有相关性？

使用scikit-learn为数据建模步骤(supervised ML process)：

1. 实例化模型。----Instantiate
2. 训练数据来拟合模型。----Fit
3. 用训练好的模型的测试数据做出预测。----Predit
4. 用指标来评估模型的好坏。---Score

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import ImputingValues as t
import seaborn as sns
%matplotlib inline

df = pd.read_csv('./survey_results_public.csv')
df.head()
 
#Only use quant variables and drop any rows with missing values
#筛选出原数据中的数值列
num_vars = df[['Salary', 'CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]
df_dropna = num_vars.dropna(axis=0)

#Split into explanatory and response variables
#将数据分为解释变量和相应变量
X = df_dropna[['CareerSatisfaction', 'HoursPerWeek', 'JobSatisfaction', 'StackOverflowSatisfaction']]
y = df_dropna['Salary']

#Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42) 

#建模
lm_model = LinearRegression(normalize=True) # Instantiate
lm_model.fit(X_train, y_train) #Fit
        
#Predict and score the model
y_test_preds = lm_model.predict(X_test) 
"The r-squared score for your model was {} on {} values.".format(r2_score(y_test, y_test_preds), len(y_test))
```



> 在建模的部分，你会发现 CRISP-DM 的步骤 3，才是真正让你获得最多信息的部分。在这个问题中，我们想要用尽可能多的特征来预测工资。用来帮助预测的变量通常被称为 **X**（即 **X 矩阵**），想要预测的变量通常称为 **y**（即 **目标向量**）。**X** 包含数据中除了 Salary 列以外的所有特征列，而 **y** 则只包含 Salary 这一列。

跟工资相关的字段：

![image-20200119112801741](image\image-20200119112801741.png)

##### （四）删除缺失值

用 sklearn 来训练，会有两个比较棘手的问题：

1. 缺失值
2. 分类变量

处理缺失值的常见方法有三种：

- 直接删除包含缺失值的行或列
- 填充缺失值
- 利用缺失值的信息构建额外特征

几种不适合删除缺失值的情形：

1. 删除调查中需要付出时间和精力给出的数据
2. 删除跟敏感信息相关的数据

除了直接移除数据，我们也可以额外创建一列来表示缺失值的信息，比如一行列中缺失值的数量，或者某一列是否包含缺失值之类。

适用删除缺失值处理方式的几种情况：

1. 在收集过程中因为机器失误导致的缺失值。
2. 缺失值位于你要预测的特征列中。

与缺失值无关，但是也应该删除数据的情况：

1. 删除不能提供有用信息的特征
2. 删除你知道包含了错误信息的特征

在删除数据的时候，你要了解这些数据缺失的原因或者数据产生错误的原因，看看能否想出比直接删除数据更好的解决方案。

> 一种常见的处理缺失值的策略，就是先查看缺失值的比例。如果某列的缺失值的占比非常大，就可以考虑删除该列。使用 Pandas 创建虚拟变量来跟踪缺失值的方法很简单，因此你可以在选择删除整列之前，先查看这些缺失值是否存在有用信息（无论缺失的比例如何）。

##### （五）填充缺失值

填充缺失值可能是数据科学团队最常用的处理缺失值的方法。常用的缺失值填充方法有:

* 均值，mean
* 中位数，median
* 如果要处理的分类变量或具有异常值的变量：众数，mode
* 机器学习方法：用其他列的数据来预测某一列的缺失值。
* 行之间相似的特性
  * K近邻算法找到相似的特征，然后用相似特征的值填充缺失值。（*所有的列都应该有匹配的特征值，只有此处存在缺失值，所以需要单独对某些值进行填充。*）
* 贝叶斯统计方法

> 不论用什么填充方式，会淡化该特征的重要性，都需要警惕方法给模型带来的**偏差（BIAS）**。虽然填充缺失值很常见，往往也能提升机器学习模型的效果，但有时候也会导致过度泛化。

![image-20200121100322061](image\image-20200121100322061.png)

![image-20200121100446527](image\image-20200121100446527.png)

##### （六）处理分类变量的方法

1. One-Hot encoding（独热编码（编码为0/1）创建虚拟变量。为分类变量里的每一个类别都创建单独的特征。
   1. 优点：
      1. 对于线性模型，能够评估每个值的权重。
      2. 在检测分类变量每个级别对目标变量的影响方面非常灵活。
      3. 每个类别对目标变量具有不同的影响能力
      4. 你不需要为分类变量的类别进行排序
      5. 比其他编码方式更容易解读
   2. 缺点：如果你的数据中有很多分类变量或者分类变量具有很多类别，而数据样本数并不大，那可能就没有办法评估每个变量对目标变量的影响。有一个不成文的规则：数据每增加一个特征，就建议增加 10 个数据点，也就是每增加 1 列就要增加 10 行数据。这是一个合理的下限，你的数据量越大越好（假设都是有代表性的数据）。
      1. 如果分类变量包含的类别非常多，会给数据添加非常多的新特征。
      2. 如果列数超多了行数，很多机器学习算法无法优化解决方案。

![image-20200121163605777](image\image-20200121163605777.png)







##### 资料连接：

[pandas.style()](https://pandas.pydata.org/pandas-docs/stable/style.html)



